{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "lib_dir = \"/home/daniele/documents/github/ftt01/phd/share/lib\"\n",
    "sys.path.insert( 0, lib_dir )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "import requests\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendCSV( filename, data, datetime_format=\"%Y-%m-%dT%H:%M:%SZ%z\" ):\n",
    "\n",
    "    # print(os.path.exists(filename))\n",
    "\n",
    "    # old_data = pd.DataFrame()\n",
    "    if os.path.exists(filename):\n",
    "        # print(\"FILE EXIST: \" + filename)\n",
    "        with open( filename ) as f:\n",
    "            old_data = pd.read_csv(f, header=0, skiprows=0, parse_dates=True, names=['values'])\n",
    "            old_data.index.name = 'datetime'\n",
    "            old_data.dropna(inplace=True)\n",
    "\n",
    "            data = data.reset_index()\n",
    "            old_data = old_data.reset_index()\n",
    "\n",
    "            data = pd.concat( [ data[data['datetime'].isin(old_data['datetime']) == False], old_data ], ignore_index=True )\n",
    "            # print(data)\n",
    "\n",
    "            f.close()\n",
    "    else:\n",
    "        mkNestedDir( getPathFromFilepath(filename) )\n",
    "        data = data.reset_index()\n",
    "\n",
    "    # print(data)\n",
    "    data.dropna(subset=['datetime'], inplace=True)\n",
    "    data.sort_values(by=['datetime'], inplace=True)\n",
    "    data['datetime'] = [ dt.datetime.strftime(c_dt, format=datetime_format) for c_dt in data['datetime'] ]\n",
    "\n",
    "    data = data.set_index('datetime')\n",
    "    data = data[data.index.notnull()]\n",
    "\n",
    "    data.to_csv( filename )\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_json(\n",
    "    station, json_complete, variable, format_data, datetime_format, current_timezone, \n",
    "    quality_check, var_1, var_2, var_3, output_path, metadata_path):\n",
    "\n",
    "    logging.debug(var_1)\n",
    "    # print(json_complete)\n",
    "\n",
    "    provider_id = None\n",
    "    provider_notes = None\n",
    "    station_id = station['codice']\n",
    "    station_name = station['nome']\n",
    "\n",
    "    x = station['longitudine']\n",
    "    y = station['latitudine']\n",
    "    z = station['quota']\n",
    "\n",
    "    if json_complete['datiOggi'][var_1] != None:\n",
    "        # dict_temp = {}\n",
    "\n",
    "        station_df = pd.DataFrame()\n",
    "        datetimes = []\n",
    "        values = []\n",
    "\n",
    "        for el in json_complete['datiOggi'][var_1][var_2]:\n",
    "\n",
    "            tmp_dt = dt_parser.parse(el['data'])\n",
    "            # tmp_dt = tmp_dt.replace(tzinfo=tz.gettz(current_timezone))\n",
    "            # datetimes.append( tmp_dt.fromtimestamp(tmp_dt.timestamp()) )\n",
    "            datetimes.append( tmp_dt.replace(tzinfo=tz.gettz(current_timezone)) )\n",
    "            values.append( el[var_3] )\n",
    "\n",
    "        #     # print(el['data'])\n",
    "\n",
    "        #     tmp_dt = dt_parser.parse(el['data'], tzinfos=tzinfos)\n",
    "        #     datetimes.append( tmp_dt.fromtimestamp(tmp_dt.timestamp(), tz=dt.timezone.utc) )\n",
    "        #     values.append( el[var_3] )\n",
    "\n",
    "        #     # dt = pd.to_datetime(el['data'], format=datetime_format).to_pydatetime()\n",
    "        #     # dt.replace(tzinfo=tz.gettz('Europe/Berlin'))\n",
    "        #     # dt = dt.astimezone(tz.gettz(\"UTC\")).replace(tzinfo=None)\n",
    "\n",
    "        #     # dict_temp[dt] = el[var_3]\n",
    "        \n",
    "        # # data_temp = appendCSV(out_temperature + st['codice'] + \".csv\", dict_temp )\n",
    "\n",
    "        station_df['datetime'] = datetimes\n",
    "        station_df['values'] = values\n",
    "\n",
    "        station_df = station_df.set_index('datetime')\n",
    "\n",
    "        sensor_id = station['codice'] + \"_\" + variable\n",
    "        \n",
    "        units = None\n",
    "        if variable == \"wind_velocity\":\n",
    "            units = el['@UM_VV']\n",
    "        if variable == \"wind_dir\":\n",
    "            units = el['@UM_DV']\n",
    "        if units == None:\n",
    "            units = el['@UM']\n",
    "            \n",
    "        datapath = output_path + station['codice'] + \".csv\"\n",
    "        metadata_path = metadata_path + station['codice'] + \".json\"\n",
    "\n",
    "        fill_metadata(\"../../etc/conf/metadata.json\", provider_name, provider_id, provider_notes,\n",
    "                station_id, station_name, x, y, z,\n",
    "                sensor_id, variable, units, format_data, quality_check, datetime_format, datapath, \n",
    "                metadata_path)\n",
    "\n",
    "        return appendCSV( datapath, station_df, datetime_format )\n",
    "    \n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    input_parser = argparse.ArgumentParser()\n",
    "    input_parser.add_argument('configuration_file', type=str)\n",
    "    args = input_parser.parse_args()\n",
    "    configuration_file = args.configuration_file\n",
    "except:\n",
    "    configuration_file = \"../../etc/conf/config.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(configuration_file) as config_file:\n",
    "    configuration = json.load(config_file)\n",
    "\n",
    "    provider_name = configuration[\"provider_name\"]\n",
    "    output_path = configuration[\"output_path\"]\n",
    "    mkNestedDir(output_path)\n",
    "    metadata_path = configuration[\"metadata_path\"]\n",
    "    mkNestedDir(metadata_path)\n",
    "    log_path = Path( configuration[\"log_path\"] )\n",
    "    mkNestedDir(log_path.parent.absolute())\n",
    "\n",
    "    datetime_format = configuration[\"datetime_format\"]\n",
    "    current_tz = configuration[\"timezone\"]\n",
    "    quality_check = configuration[\"quality_check\"]\n",
    "\n",
    "    if configuration[\"logging_level\"] == \"info\":\n",
    "        logging_level = logging.INFO\n",
    "    elif configuration[\"logging_level\"] == \"debug\":\n",
    "        logging_level = logging.DEBUG\n",
    "    else:\n",
    "        logging_level = logging.ERROR\n",
    "\n",
    "config_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    # filename=log_path + dt.datetime.today().strftime(\"%Y%m%d%H%M%S\") + \".log\",\n",
    "    filename = log_path,\n",
    "    format = '%(asctime)s - %(message)s',\n",
    "    filemode = 'a',\n",
    "    level = logging_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://dati.meteotrentino.it/service.asmx/listaStazioni\"\n",
    "\n",
    "data = requests.get(url)\n",
    "xpars = xmltodict.parse(data.text)\n",
    "json_complete = json.loads(json.dumps(xpars))\n",
    "stations = json_complete['ArrayOfAnagrafica']['anagrafica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycodes = []\n",
    "n_codes = 0\n",
    "for st in stations:\n",
    "    mycodes.append( st['codice'] )\n",
    "    n_codes = n_codes + 1\n",
    "\n",
    "logging.info(\"Number of stations online: \" + str(n_codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for st in stations:\n",
    "\n",
    "    logging.debug(\"Downloading..\" + st['codice'])\n",
    "    url = \"http://dati.meteotrentino.it/service.asmx/ultimiDatiStazione?codice={station_code}\"\n",
    "    logging.debug(url.format(station_code=st['codice']))\n",
    "    \n",
    "    data = requests.get(url.format(station_code=st['codice']))\n",
    "    \n",
    "    xpars = xmltodict.parse(data.text)\n",
    "    json_complete = json.loads(json.dumps(xpars))\n",
    "\n",
    "    logging.debug(\"JSON data: \" + str(json_complete))\n",
    "    decode_json(\n",
    "        st, json_complete, \"temperature\", \"float\", datetime_format, current_tz, quality_check, \n",
    "        \"temperature\", \"temperatura_aria\", \"temperatura\", \n",
    "        output_path + \"temperature/\", metadata_path)\n",
    "    decode_json(\n",
    "        st, json_complete, \"precipitation\", \"float\", datetime_format, current_tz, quality_check,\n",
    "        \"precipitazioni\", \"precipitazione\", \"pioggia\", \n",
    "        output_path + \"precipitation/\", metadata_path)\n",
    "    decode_json(\n",
    "        st, json_complete, \"wind_velocity\", \"float\", datetime_format, current_tz, quality_check,\n",
    "        \"venti\", \"vento_al_suolo\", \"v\", \n",
    "        output_path + \"wind/\", metadata_path)\n",
    "    decode_json(\n",
    "        st, json_complete, \"wind_dir\", \"float\", datetime_format, current_tz, quality_check,\n",
    "        \"venti\", \"vento_al_suolo\", \"d\", \n",
    "        output_path + \"wind_dir/\", metadata_path)\n",
    "    decode_json(\n",
    "        st, json_complete, \"global_radiation\", \"float\", datetime_format, current_tz, quality_check,\n",
    "        \"radiazione\", \"radiazioneglobale\", \"rsg\", \n",
    "        output_path + \"radiation/\", metadata_path)\n",
    "    decode_json(\n",
    "        st, json_complete, \"relative_humidity\", \"float\", datetime_format, current_tz, quality_check,\n",
    "        \"umidita_relativa\", \"umidita_relativa\", \"rh\", \n",
    "        output_path + \"relative_humidity/\", metadata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"DONE!\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "63d5e5d3ef3ec13453f007c86728ea82bf14ea96ebb0a2fb9c639ae49af1dbf7"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
