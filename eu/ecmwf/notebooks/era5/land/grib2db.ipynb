{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "lib_dir = \"/home/daniele/documents/github/ftt01/phd/share/lib\"\n",
    "sys.path.insert( 0, lib_dir )\n",
    "\n",
    "from lib import *\n",
    "import subprocess\n",
    "import psycopg2\n",
    "import random\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Input():\n",
    "    def add_start_date(self, start_date):\n",
    "        self.start_date = start_date\n",
    "    def add_end_date(self, end_date):\n",
    "        self.end_date = end_date\n",
    "    def add_file(self, file):\n",
    "        self.file = file\n",
    "    def add_variable(self, variable):\n",
    "        self.variable = variable\n",
    "\n",
    "input_parser = argparse.ArgumentParser()\n",
    "input_parser.add_argument('-s','--start_date', type=str, nargs='?', default=\"2010-01-01T00:00:00\")\n",
    "input_parser.add_argument('-e','--end_date', type=str, nargs='?', default=\"2022-12-31T23:00:00\")\n",
    "input_parser.add_argument('-f','--file', type=str, nargs='?', default=None)\n",
    "input_parser.add_argument('-v','--variables', type=list, nargs='?', default=['tp','2t'])\n",
    "args = input_parser.parse_args()\n",
    "\n",
    "input_path = \"/media/lacie2022/data/meteo/ecmwf/era5/land/\"\n",
    "tmp_path = \"/media/lacie2022/data/meteo/ecmwf/era5/land/tmp/\"\n",
    "mkNestedDir( tmp_path )\n",
    "\n",
    "if args.file == None:\n",
    "    args.files = [\n",
    "    \"20102011.grib\",\n",
    "    \"20162017.grib\",\n",
    "    \"2020_11.grib\",\n",
    "    \"2020_2.grib\",\n",
    "    \"2020_5.grib\",\n",
    "    \"2020_8.grib\",\n",
    "    \"2021_11.grib\",\n",
    "    \"2021_2.grib\",\n",
    "    \"2021_5.grib\",\n",
    "    \"2021_8.grib\",\n",
    "    \"20122013.grib\",\n",
    "    \"20182019.grib\",\n",
    "    \"2020_12.grib\",\n",
    "    \"2020_3.grib\",\n",
    "    \"2020_6.grib\",\n",
    "    \"2020_9.grib\",\n",
    "    \"2021_12.grib\",\n",
    "    \"2021_3.grib\",\n",
    "    \"2021_6.grib\",\n",
    "    \"2021_9.grib\",\n",
    "    \"20142015.grib\",\n",
    "    \"2020_10.grib\",\n",
    "    \"2020_1.grib\",\n",
    "    \"2020_4.grib\",\n",
    "    \"2020_7.grib\",\n",
    "    \"2021_10.grib\",\n",
    "    \"2021_1.grib\",\n",
    "    \"2021_4.grib\",\n",
    "    \"2021_7.grib\"]\n",
    "else:\n",
    "    args.files = [args.file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = dt.datetime.strptime( args.start_date, '%Y-%m-%dT%H:%M:%S' )\n",
    "end_date = dt.datetime.strptime( args.end_date, '%Y-%m-%dT%H:%M:%S' )\n",
    "dates = pd.date_range(start_date, end_date, freq='1H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_postgres_connection():\n",
    "\n",
    "    db_name = 'meteo'\n",
    "    db_user = 'postgres'\n",
    "    db_password = 'pgAifa2Bias?'\n",
    "    db_host = '172.20.0.2'\n",
    "\n",
    "    return psycopg2.connect(database=db_name, user=db_user, password=db_password, host=db_host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_point( y, x, epsg=4326, tolerance=0.01 ):\n",
    "\n",
    "    c_id = None\n",
    "\n",
    "    sql_exist = '''\n",
    "        SELECT COUNT(*)\n",
    "        FROM ecmwf.era5_land_points\n",
    "        WHERE ST_Contains(\n",
    "            ST_Transform(\n",
    "                ST_MakeEnvelope({min_lon}, {min_lat}, {max_lon}, {max_lat}, {epsg}), 4326 ),\n",
    "            era5_land_points.geom)\n",
    "        LIMIT 1;'''\n",
    "\n",
    "    min_lat = y - tolerance\n",
    "    max_lat = y + tolerance\n",
    "    min_lon = x - tolerance\n",
    "    max_lon = x + tolerance\n",
    "\n",
    "    sql_exist = sql_exist.format(\n",
    "        min_lat=min_lat,\n",
    "        min_lon=min_lon,\n",
    "        max_lat=max_lat,\n",
    "        max_lon=max_lon,\n",
    "        epsg=epsg\n",
    "    )\n",
    "    \n",
    "    # print(sql_exist)\n",
    "\n",
    "    sql_insert = '''\n",
    "        INSERT INTO ecmwf.era5_land_points(geom)\n",
    "        VALUES ( ST_SetSRID(ST_MakePoint({x},{y}),{epsg}) )\n",
    "        ON CONFLICT DO NOTHING;'''.format(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            epsg=epsg\n",
    "    )\n",
    "\n",
    "    sql_select = '''\n",
    "        SELECT ecmwf.era5_land_points.id\n",
    "        FROM ecmwf.era5_land_points\n",
    "        ORDER BY ecmwf.era5_land_points.geom <#> ST_SetSRID(ST_MakePoint({x},{y}),{epsg})\n",
    "        LIMIT 1;'''.format(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            epsg=epsg\n",
    "        )\n",
    "    \n",
    "    # print(sql_select)\n",
    "\n",
    "    conn = get_postgres_connection()\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            # print(sql_insert)\n",
    "            # cur.execute(sql_insert)\n",
    "            # conn.commit()\n",
    "\n",
    "            # cur.execute(sql_select)\n",
    "            # c_id = int(cur.fetchall()[0][0])\n",
    "            cur.execute(sql_exist)\n",
    "            rows = cur.fetchall()\n",
    "            if rows[0][0] != 0:\n",
    "                cur.execute(sql_select)\n",
    "                c_id = int(cur.fetchall()[0][0])\n",
    "            else:\n",
    "                print(sql_insert)\n",
    "                cur.execute(sql_insert)\n",
    "                conn.commit()\n",
    "                cur.execute(sql_select)\n",
    "                c_id = int(cur.fetchall()[0][0])\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "    return c_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data( y, x, epsg, datetime_UTC, value, variable, um ):\n",
    "\n",
    "    # print(point)\n",
    "\n",
    "    sql_insert = '''\n",
    "        INSERT INTO ecmwf.era5_land_values(\n",
    "\t        datetime, value, point, variable, um)\n",
    "\t    VALUES ('{datetime}'::timestamp, {value},\n",
    "            (\n",
    "                SELECT ecmwf.era5_land_points.id\n",
    "                FROM ecmwf.era5_land_points\n",
    "                ORDER BY ST_Distance(ST_SetSRID(ST_MakePoint({x},{y}),{epsg}), ecmwf.era5_land_points.geom)\n",
    "                LIMIT 1\n",
    "            ), '{variable}', '{um}')\n",
    "        ON CONFLICT DO NOTHING;'''.format(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            epsg=epsg,\n",
    "            datetime=datetime_UTC, \n",
    "            value=value, \n",
    "            variable=variable,\n",
    "            um=um\n",
    "        )\n",
    "    print(sql_insert)\n",
    "    \n",
    "    conn = get_postgres_connection()\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(sql_insert)\n",
    "            conn.commit()\n",
    "    finally:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_on_db( date, var_meta, n_points:int, c_file ):\n",
    "\n",
    "    c_ens_df = pd.read_csv(c_file, nrows=n_points, sep='\\s+')\n",
    "    c_ens_df = c_ens_df.rename(columns={'Value':1})\n",
    "    \n",
    "    c_ens_df = c_ens_df.set_index(['Latitude','Longitude'])\n",
    "\n",
    "    for idx in c_ens_df.index:\n",
    "\n",
    "        lat = idx[0]\n",
    "        lon = idx[1]\n",
    "        c_id = add_point( lat, lon, epsg=4326 )\n",
    "        add_data( lat, lon, 4326, date, c_ens_df.loc[idx].values[0], var_meta[0], var_meta[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(c_file, model_varname):\n",
    "\n",
    "    tmp_txt = dt.datetime.strftime(\n",
    "        dt.datetime.now(),\n",
    "        format=\"%Y%m%dT%H%M%S\") + '_' + str(random.randint(1,100000)) + \"_\" + model_varname\n",
    "\n",
    "    if model_varname == 'tp':\n",
    "        variable = 'tp'\n",
    "        um = 'm'\n",
    "\n",
    "    elif model_varname == '2t':\n",
    "        variable = '2t'\n",
    "        um = 'K'\n",
    "\n",
    "    ## create a file for each variable\n",
    "    pre_cmd = '''cdo -selname,{var} {input_path}{file_grib} {input_path}{var}_{file_grib}'''.format(\n",
    "        var = model_varname,\n",
    "        input_path = input_path,\n",
    "        file_grib = c_file\n",
    "    )\n",
    "    print(pre_cmd)\n",
    "    pre_process = subprocess.Popen(pre_cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    stdout, stderr = pre_process.communicate()\n",
    "\n",
    "    if ('Error' in str(stderr)):\n",
    "        print(stderr)\n",
    "        return None\n",
    "    else:\n",
    "        ## read the meta info in a table with cdo\n",
    "        meta_cmd = '''cdo -info {input_path}{var}_{file_grib} > {tmp_path}meta{tmp_txt}.txt'''.format(\n",
    "            var = model_varname,\n",
    "            input_path = input_path,\n",
    "            file_grib = c_file,\n",
    "            tmp_path = tmp_path,\n",
    "            tmp_txt = tmp_txt\n",
    "        )\n",
    "        print(meta_cmd)\n",
    "        process = subprocess.Popen(meta_cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        stdout, stderr = process.communicate()\n",
    "\n",
    "    if ('Error' in str(stderr)):\n",
    "        print(stderr)\n",
    "        return None\n",
    "    else:\n",
    "        ## load the meta\n",
    "        df_meta = pd.read_csv('''{tmp_path}meta{tmp_txt}.txt'''.format(\n",
    "            tmp_path = tmp_path,\n",
    "            tmp_txt = tmp_txt\n",
    "            ), sep='\\s+'\n",
    "        )\n",
    "\n",
    "    for idx in df_meta.index:\n",
    "        try:\n",
    "            ts = int(df_meta.loc[idx]['-1'])\n",
    "        except:\n",
    "            break\n",
    "\n",
    "        c_date = dt.datetime.strptime(\n",
    "            df_meta.loc[idx]['Date'] + 'T' + df_meta.loc[idx]['Time'],\n",
    "            \"%Y-%m-%dT%H:%M:%S\")\n",
    "        \n",
    "        if not(c_date in dates):\n",
    "            continue\n",
    "\n",
    "        n_points = df_meta.loc[idx]['Gridsize']\n",
    "    \n",
    "        pre_cmd = '''cdo -seltimestep,{step} {input_path}{var}_{file_grib} {input_path}tmp_{idx}_{var}_{file_grib}'''.format(\n",
    "            var = model_varname,\n",
    "            step = ts,\n",
    "            input_path = input_path,\n",
    "            idx = idx,\n",
    "            file_grib = c_file\n",
    "        )\n",
    "        print(pre_cmd)\n",
    "        process = subprocess.Popen(pre_cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        stdout, stderr = process.communicate()\n",
    "            \n",
    "        cmd = '''grib_get_data {input_path}tmp_{idx}_{var}_{file_grib} >> {tmp_path}{tmp_txt}.txt'''.format(\n",
    "            idx = idx,\n",
    "            file_grib = c_file,\n",
    "            input_path = input_path,\n",
    "            tmp_path = tmp_path,\n",
    "            tmp_txt=tmp_txt,\n",
    "            var = model_varname\n",
    "        )\n",
    "        print(cmd)\n",
    "        process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        stdout, stderr = process.communicate()\n",
    "\n",
    "        load_on_db( c_date, (variable, um), int(n_points), tmp_path + '{tmp_txt}.txt'.format(tmp_txt=tmp_txt) )\n",
    "\n",
    "        try:\n",
    "            os.remove( tmp_path + '{tmp_txt}.txt'.format(tmp_txt=tmp_txt) )\n",
    "            os.remove( '{input_path}tmp_{idx}_{var}_{file_grib}'''.format(\n",
    "                input_path = input_path,\n",
    "                idx = idx,\n",
    "                file_grib = c_file,\n",
    "                var = model_varname\n",
    "                )\n",
    "            )\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract( c_file ):\n",
    "    print('Processing: ' + str(c_file))\n",
    "\n",
    "    for v in args.variables:\n",
    "        execute(c_file, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a process pool that uses all cpus\n",
    "pool = multiprocessing.Pool()\n",
    "with multiprocessing.Pool() as pool:\n",
    "    pool.map(extract, args.files)\n",
    "# close the process pool\n",
    "pool.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
