{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "lib_dir = \"/home/daniele/documents/github/ftt01/phd/share/lib\"\n",
    "sys.path.insert( 0, lib_dir )\n",
    "\n",
    "from lib import *\n",
    "import subprocess\n",
    "import psycopg2\n",
    "# import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class local_args():\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def add_latitude(self,  latitude):\n",
    "        self.latitude = latitude\n",
    "\n",
    "    def add_longitude(self,  longitude):\n",
    "        self.longitude = longitude\n",
    "    \n",
    "    def add_neighbors(self,  nn):\n",
    "        self.neighbors = nn\n",
    "\n",
    "    def add_start_date(self,  start_date):\n",
    "        self.start_date = start_date\n",
    "    \n",
    "    def add_end_date(self,  end_date):\n",
    "        self.end_date = end_date\n",
    "\n",
    "    def add_variable(self,  variable):\n",
    "        self.variable = variable\n",
    "    \n",
    "    def add_meta_grid(self,  meta_grid):\n",
    "        self.meta_grid = meta_grid\n",
    "\n",
    "    def add_output_path(self,  output_path):\n",
    "        self.output_path = output_path\n",
    "        mkNestedDir( output_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "# input_parser = argparse.ArgumentParser()\n",
    "# input_parser.add_argument('polygon', type=str)\n",
    "# input_parser.add_argument('start_date', type=str)\n",
    "# input_parser.add_argument('end_date', type=str)\n",
    "# input_parser.add_argument('variable', type=str)\n",
    "# input_parser.add_argument('output_path', type=str)\n",
    "# input_parser.add_argument('meta_grid', type=str)\n",
    "# args = input_parser.parse_args()\n",
    "# except:\n",
    "args = local_args()\n",
    "args.add_start_date(\"2010-01-01T00:00:00\")\n",
    "args.add_end_date(\"2019-12-31T23:59:00\")\n",
    "args.add_variable(\"2t\")\n",
    "args.add_output_path(\"/media/windows/projects/bias_correction/applications/era5land/data/pre_processed/\")\n",
    "args.add_meta_grid(\"/media/windows/projects/bias_correction/applications/era5land/data/pre_processed/grid.csv\")\n",
    "args.add_latitude(46.42)\n",
    "args.add_longitude(10.95)\n",
    "args.add_neighbors(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.features = pd.DataFrame()\n",
    "        self.outputs = pd.DataFrame()\n",
    "        self.start_date = pd.to_datetime(\n",
    "            dt.datetime.strptime(\n",
    "                \"19500101T00:00\", \"%Y%m%dT%H:%M\"))\n",
    "        self.end_date = pd.to_datetime( dt.datetime.now() )\n",
    "    \n",
    "    def add_output(self, df, name, ffill=(False,None)):\n",
    "        df = df.rename(columns={df.columns[0]:name})\n",
    "        if ffill[0] is True:\n",
    "            df = df.fillna(method=\"ffill\").replace(np.NaN, ffill[1])\n",
    "        self.outputs = pd.concat([self.outputs, df], axis=1)\n",
    "        \n",
    "    def add_feature(self, df, name, ffill=(False,None)):\n",
    "        df = df.rename(columns={df.columns[0]:name})\n",
    "        if ffill[0] is True:\n",
    "            # print(\"filling\")\n",
    "            df = df.fillna(method=\"ffill\").replace(np.NaN, ffill[1])\n",
    "        self.features = pd.concat([self.features, df], axis=1)\n",
    "    \n",
    "    def update_dates(self):\n",
    "        start_date = self.outputs.index[0]\n",
    "        end_date = self.outputs.index[-1]\n",
    "\n",
    "        if start_date > self.start_date:\n",
    "            self.start_date = start_date\n",
    "        \n",
    "        if end_date < self.end_date:\n",
    "            self.end_date = end_date\n",
    "    \n",
    "    def batch_data(self, start_date, prediction_hour, lag_hours, lead_hours):\n",
    "        \n",
    "        c_start_date = dt.datetime(start_date.year, start_date.month, start_date.day, prediction_hour)\n",
    "\n",
    "        ## lag hours\n",
    "        c_end_date = c_start_date - dt.timedelta(hours=1)\n",
    "        c_lag_date = c_end_date - dt.timedelta( hours = lag_hours )\n",
    "        if self.start_date > c_lag_date:\n",
    "            first_available = self.start_date + dt.timedelta( hours = lag_hours )\n",
    "            raise Exception(f\"Start date not allowed: {start_date}, first available {first_available}\")\n",
    "        lag_block = self.features[c_lag_date:c_end_date]\n",
    "        \n",
    "        ## lead hours\n",
    "        c_end_forecast = c_start_date + dt.timedelta(hours=lead_hours)\n",
    "        lead_block = self.outputs[c_start_date:c_end_forecast]\n",
    "\n",
    "        # print(f\"Lag dates: {lag_block.index}\")\n",
    "        # print(f\"Start date: {c_start_date}\")\n",
    "        # print(f\"Lead dates: {lead_block.index}\")\n",
    "\n",
    "        return lag_block, lead_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = dt.datetime.strptime( args.start_date, '%Y-%m-%dT%H:%M:%S' )\n",
    "end_date = dt.datetime.strptime( args.end_date, '%Y-%m-%dT%H:%M:%S' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "    \"2t\",\n",
    "    \"tp\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Data()\n",
    "\n",
    "for v in variables:\n",
    "\n",
    "    if (v == \"tp\"):\n",
    "        ffill = (True,0)\n",
    "    else:\n",
    "        ffill = (False,None)\n",
    "\n",
    "    df = extract_era5land(start_date, end_date, v, args.latitude, args.longitude, args.neighbors)\n",
    "    df_streamflow = extract_pab(start_date, end_date, 'Q', args.latitude, args.longitude)\n",
    "   \n",
    "    for i in range(args.neighbors):\n",
    "        test.add_feature(df[[df.columns[i]]], v, ffill=ffill)\n",
    "        \n",
    "test.add_output(df_streamflow[[df_streamflow.columns[i]]], \"streamflow\", ffill=(False,0))\n",
    "test.update_dates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_hours = 24\n",
    "lag_hours = 24\n",
    "\n",
    "prediction_hour = 10\n",
    "prediction_interval = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_blocks = []\n",
    "outputs_blocks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = test.end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-12-31 23:00:00', freq='H')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_of_dates = False\n",
    "c_start_date = start_date + dt.timedelta(hours=lag_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2010, 1, 2, 0, 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lag_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current start date: 2010-03-27 00:00:00\n",
      "Block lag length: 25\n",
      "Block lead length: 25\n",
      "Current start date: 2011-03-26 00:00:00\n",
      "Block lag length: 25\n",
      "Block lead length: 25\n",
      "Current start date: 2017-02-14 00:00:00\n",
      "Block lag length: 25\n",
      "Block lead length: 25\n",
      "Current start date: 2017-02-15 00:00:00\n",
      "Block lag length: 25\n",
      "Block lead length: 25\n",
      "Current start date: 2017-02-22 00:00:00\n",
      "Block lag length: 25\n",
      "Block lead length: 25\n",
      "Current start date: 2017-02-23 00:00:00\n",
      "Block lag length: 25\n",
      "Block lead length: 25\n",
      "Current start date: 2017-02-24 00:00:00\n",
      "Block lag length: 25\n",
      "Block lead length: 25\n",
      "Current start date: 2017-02-25 00:00:00\n",
      "Block lag length: 25\n",
      "Block lead length: 25\n",
      "Current start date: 2017-04-17 00:00:00\n",
      "Block lag length: 25\n",
      "Block lead length: 25\n",
      "Current start date: 2017-07-05 00:00:00\n",
      "Block lag length: 25\n",
      "Block lead length: 25\n",
      "Current start date: 2017-07-06 00:00:00\n",
      "Block lag length: 25\n",
      "Block lead length: 25\n",
      "Current start date: 2018-07-03 00:00:00\n",
      "Block lag length: 25\n",
      "Block lead length: 25\n",
      "Current start date: 2018-09-06 00:00:00\n",
      "Block lag length: 25\n",
      "Block lead length: 25\n",
      "Current start date: 2018-12-03 00:00:00\n",
      "Block lag length: 25\n",
      "Block lead length: 25\n",
      "Current start date: 2019-01-27 00:00:00\n",
      "Block lag length: 25\n",
      "Block lead length: 25\n"
     ]
    }
   ],
   "source": [
    "while end_of_dates is False:\n",
    "    \n",
    "    c_end_date = c_start_date + dt.timedelta(hours=lead_hours)\n",
    "    if c_end_date > end_date:\n",
    "        # print(\"HERE\")\n",
    "        break\n",
    "\n",
    "    lag_block, lead_block = test.batch_data(c_start_date, prediction_hour, lag_hours, lead_hours)\n",
    "\n",
    "    # print(f\"Lag block length: {lag_block.shape[0]}\")\n",
    "    # print(f\"Lead block length: {lead_block.shape[0]}\")\n",
    "\n",
    "    if (lag_block.shape[0] == lag_hours+1) and \\\n",
    "        (lead_block.shape[0] == lag_hours+1) and \\\n",
    "            not((lag_block.isna().any().any()) or \\\n",
    "                (lead_block.isna().any().any())):\n",
    "\n",
    "        features_blocks.append(lag_block.values.tolist())\n",
    "        outputs_blocks.append(lead_block.values.tolist())\n",
    "\n",
    "    else:\n",
    "        print(f\"Current start date: {c_start_date}\")\n",
    "\n",
    "        print(f\"Block lag length: {lag_block.shape[0]}\")\n",
    "        print(f\"Block lead length: {lead_block.shape[0]}\")\n",
    "        \n",
    "        # print(f\"Block lag: {lag_block}\")\n",
    "        # print(f\"Block lead: {lead_block}\")\n",
    "\n",
    "    c_start_date = c_start_date + dt.timedelta(hours=prediction_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Function\n",
    "\n",
    "class DataBuilder(Dataset):\n",
    "    def __init__(self, x, y, device):\n",
    "        self.device = device\n",
    "        self.x = self.numpyToTensor(x)\n",
    "        self.y = self.numpyToTensor(y)\n",
    "        self.len = self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):      \n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def numpyToTensor(self,x):\n",
    "        return torch.from_numpy(x).to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_blocks = np.array(features_blocks).astype(\"float32\")\n",
    "outputs_blocks = np.array(outputs_blocks).astype(\"float32\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset = DataBuilder( features_blocks, outputs_blocks, device )\n",
    "\n",
    "dataset.x.shape\n",
    "dataset.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3635, 25, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3635, 25, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for each member of the ensemble [neighbors]\n",
    "### create a dataset\n",
    "### batch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = start_date + dt.timedelta( hours = lag_hours )\n",
    "c_start_date = dt.datetime(start_date.year, start_date.month, start_date.day, prediction_hour)\n",
    "c_end_forecast = c_start_date + dt.timedelta(hours=lead_hours)\n",
    "\n",
    "c_lag_date = c_start_date - dt.timedelta(hours=lag_hours)\n",
    "\n",
    "lag_block = test.dataset[c_lag_date:c_start_date]\n",
    "c_start_forecast = c_start_date+dt.timedelta(hours=1)\n",
    "lead_block = test.dataset[c_start_forecast:c_end_forecast]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_lag_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_end_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[\"2010-01-01 00:00\":\"2010-01-03 00:00\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.plot(figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = args.output_path + args.variable + '_' + start_date.strftime('%Y%m%dT%H%M%S') + '_' + end_date.strftime('%Y%m%dT%H%M%S') + '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_csv( output_filename )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
