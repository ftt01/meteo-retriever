{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "lib_dir = \"/home/daniele/documents/github/ftt01/phd/share/lib\"\n",
    "sys.path.insert( 0, lib_dir )\n",
    "\n",
    "from lib import *\n",
    "import subprocess\n",
    "import psycopg2\n",
    "# import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class local_args():\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def add_start_date(self,  start_date):\n",
    "        self.start_date = start_date\n",
    "    \n",
    "    def add_end_date(self,  end_date):\n",
    "        self.end_date = end_date\n",
    "\n",
    "    def add_variable(self,  variable):\n",
    "        self.variable = variable\n",
    "    \n",
    "    def add_meta_grid(self,  meta_grid):\n",
    "        self.meta_grid = meta_grid\n",
    "\n",
    "    def add_output_path(self,  output_path):\n",
    "        self.output_path = output_path\n",
    "        mkNestedDir( output_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = local_args()\n",
    "args.add_start_date(\"2010-01-01T00:00:00\")\n",
    "args.add_end_date(\"2019-12-31T23:59:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = dt.datetime.strptime( args.start_date, '%Y-%m-%dT%H:%M:%S' )\n",
    "end_date = dt.datetime.strptime( args.end_date, '%Y-%m-%dT%H:%M:%S' )\n",
    "aggregation_at = '1H'\n",
    "dates = pd.date_range(start_date, end_date, freq=aggregation_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_postgres_connection():\n",
    "\n",
    "    db_name = 'meteo'\n",
    "    db_user = 'postgres'\n",
    "    db_password = 'pgAifa2Bias?'\n",
    "    db_host = '172.20.0.2'\n",
    "\n",
    "    return psycopg2.connect(database=db_name, user=db_user, password=db_password, host=db_host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_point( y, x, epsg=4326, tolerance=0.01 ):\n",
    "\n",
    "    c_id = None\n",
    "\n",
    "    sql_exist = '''\n",
    "        SELECT COUNT(*)\n",
    "        FROM ecmwf.era5_points\n",
    "        WHERE ST_Contains(\n",
    "            ST_Transform(\n",
    "                ST_MakeEnvelope({min_lon}, {min_lat}, {max_lon}, {max_lat}, {epsg}), 4326 ),\n",
    "            era5_points.geom)\n",
    "        LIMIT 1;'''\n",
    "\n",
    "    min_lat = y - tolerance\n",
    "    max_lat = y + tolerance\n",
    "    min_lon = x - tolerance\n",
    "    max_lon = x + tolerance\n",
    "\n",
    "    sql_exist = sql_exist.format(\n",
    "        min_lat=min_lat,\n",
    "        min_lon=min_lon,\n",
    "        max_lat=max_lat,\n",
    "        max_lon=max_lon,\n",
    "        epsg=epsg\n",
    "    )\n",
    "\n",
    "    sql_select = '''\n",
    "        SELECT ecmwf.era5_points.id\n",
    "        FROM ecmwf.era5_points\n",
    "        ORDER BY ecmwf.era5_points.geom <#> ST_SetSRID(ST_MakePoint({x},{y}),{epsg})\n",
    "        LIMIT 1;'''.format(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            epsg=epsg\n",
    "        )\n",
    "    \n",
    "    # print(sql_select)\n",
    "\n",
    "    conn = get_postgres_connection()\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(sql_exist)\n",
    "            rows = cur.fetchall()\n",
    "            if rows[0][0] != 0:\n",
    "                cur.execute(sql_select)\n",
    "                c_id = int(cur.fetchall()[0][0])\n",
    "            else:\n",
    "                print(\"Not existing point!\")\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "    return c_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_to_dataframe(conn, query, column_names):\n",
    "\n",
    "    # print(query)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    # The execute returns a list of tuples:\n",
    "    tuples_list = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    # Now we need to transform the list into a pandas DataFrame:\n",
    "    df = pd.DataFrame(tuples_list, columns=column_names)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.DataFrame(index=dates)\n",
    "full_df.index.name = 'datetime'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_get_data_metadata_tp = '''\n",
    "SELECT datetime, value\n",
    "FROM ecmwf.era5_values\n",
    "WHERE datetime >= '{start_datetime}' \n",
    "    AND datetime <= '{end_datetime}' \n",
    "    AND variable = '{variable}'\n",
    "    AND point = {c_id}\n",
    "GROUP BY datetime, value\n",
    "ORDER BY datetime\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_get_data_geom_tp = '''\n",
    "WITH inner_points AS (\n",
    "    WITH poly AS (\n",
    "        SELECT ST_Buffer(geom::geography, 5000)::geometry as geom\n",
    "        FROM geometries.eu_ita_regions\n",
    "        WHERE name = 'Trentino-Alto Adige'\n",
    "    ),\n",
    "    points AS (\n",
    "        SELECT id, geom\n",
    "        FROM ecmwf.era5_points\n",
    "    )\n",
    "    SELECT points.id as id, points.geom\n",
    "    FROM points, poly\n",
    "    WHERE ST_Contains(poly.geom, points.geom)\n",
    ")\n",
    "SELECT point, datetime, value\n",
    "FROM ecmwf.era5_values, inner_points\n",
    "WHERE datetime >= '{start_datetime}' \n",
    "    AND datetime <= '{end_datetime}' \n",
    "    AND variable = '{variable}'\n",
    "    AND point = inner_points.id\n",
    "GROUP BY point, datetime, value\n",
    "ORDER BY point, datetime\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_get_data_metadata_2t = '''\n",
    "SELECT datetime, value \n",
    "FROM ecmwf.era5_values\n",
    "WHERE datetime >= '{start_datetime}' \n",
    "    AND datetime <= '{end_datetime}' \n",
    "    AND variable = '{variable}'\n",
    "    AND point = {c_id}\n",
    "ORDER BY datetime\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_get_data_geom_2t = '''\n",
    "WITH inner_points AS (\n",
    "    WITH poly AS (\n",
    "        SELECT ST_Buffer(geom::geography, 5000)::geometry as geom\n",
    "        FROM geometries.eu_ita_regions\n",
    "        WHERE name = 'Trentino-Alto Adige'\n",
    "    ),\n",
    "    points AS (\n",
    "        SELECT id, geom\n",
    "        FROM ecmwf.era5_points\n",
    "    )\n",
    "    SELECT points.id as id, points.geom\n",
    "    FROM points, poly\n",
    "    WHERE ST_Contains(poly.geom, points.geom)\n",
    ")\n",
    "SELECT point, datetime, value\n",
    "FROM ecmwf.era5_values, inner_points\n",
    "WHERE datetime >= '{start_datetime}' \n",
    "    AND datetime <= '{end_datetime}' \n",
    "    AND variable = '{variable}'\n",
    "    AND point = inner_points.id\n",
    "GROUP BY point, datetime, value\n",
    "ORDER BY point, datetime\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_id(c_id):\n",
    "    sql_get_data = sql_get_data_metadata_tp.format(\n",
    "        start_datetime = (start_date-dt.timedelta(hours=1)).strftime('%Y-%m-%d %H:%M'),\n",
    "        end_datetime = end_date.strftime('%Y-%m-%d %H:%M'),\n",
    "        variable = 'tp',\n",
    "        c_id = c_id\n",
    "    )\n",
    "    # print(sql_get_data)\n",
    "    c_df = sql_to_dataframe( get_postgres_connection(), sql_get_data, column_names = ['datetime', 'value'])\n",
    "    c_df.set_index('datetime', inplace=True)\n",
    "    ### put the old_id or the c_id in the columns of full_df\n",
    "    c_df.rename(columns={'value':c_id}, inplace=True)\n",
    "\n",
    "    ## precipitation\n",
    "    c_df = resample_timeseries( \n",
    "        c_df, res_type='sum', \n",
    "        step=aggregation_at, offset=False )\n",
    "    # from meters to mm\n",
    "    c_df = c_df * 1000\n",
    "    c_df = c_df[start_date:end_date]\n",
    "\n",
    "    precipitation_era5_df = pd.concat([full_df,c_df], axis=1, join='inner')\n",
    "    precipitation_era5_df[c_id] = [ round(float(v),3) for v in precipitation_era5_df[c_id].values ]\n",
    "    precipitation_era5_df.rename(columns={c_id:'values'}, inplace=True)\n",
    "\n",
    "    #########################\n",
    "\n",
    "    sql_get_data = sql_get_data_metadata_2t.format(\n",
    "            start_datetime = start_date.strftime('%Y-%m-%d %H:%M'),\n",
    "            end_datetime = end_date.strftime('%Y-%m-%d %H:%M'),\n",
    "            variable = '2t',\n",
    "            c_id = c_id\n",
    "        )\n",
    "    c_df = sql_to_dataframe( get_postgres_connection(), sql_get_data, column_names = ['datetime', 'value'])\n",
    "    c_df.set_index('datetime', inplace=True)\n",
    "    ### put the old_id or the c_id in the columns of full_df\n",
    "    c_df.rename(columns={'value':c_id}, inplace=True)\n",
    "\n",
    "    ## temperature\n",
    "    c_df = resample_timeseries( \n",
    "        c_df, res_type='mean', \n",
    "        step=aggregation_at, offset=False )\n",
    "    # from Kelvin to Celsius\n",
    "    c_df = c_df - 273.15\n",
    "\n",
    "    temperature_era5_df = pd.concat([full_df,c_df], axis=1, join='inner')\n",
    "    temperature_era5_df[c_id] = [ round(float(v),3) for v in temperature_era5_df[c_id].values ]\n",
    "    temperature_era5_df.rename(columns={c_id:'values'}, inplace=True)\n",
    "\n",
    "    return precipitation_era5_df,temperature_era5_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '/media/windows/projects/conferences/EUG23/data/era5/'\n",
    "mkNestedDir( output_path + 'precipitation' )\n",
    "mkNestedDir( output_path + 'temperature' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_point(lat,lon,name,output_path):\n",
    "    c_id = get_point(lat,lon)\n",
    "    precipitation_era5,temperature_era5 = get_data_id(c_id)\n",
    "\n",
    "    precipitation_era5.to_csv(output_path+'precipitation/'+name+'.csv')\n",
    "    temperature_era5.to_csv(output_path+'temperature/'+name+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Senales\n",
    "save_point(lat=46.57, lon=11.03, name='senales', output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passirio\n",
    "save_point(lat=46.82, lon=11.28, name='passirio', output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Val di Sole\n",
    "save_point(lat=46.32, lon=10.78, name='valdisole', output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
