{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "lib_dir = \"/home/daniele/documents/github/ftt01/phd/share/lib\"\n",
    "sys.path.insert( 0, lib_dir )\n",
    "\n",
    "from lib import *\n",
    "import subprocess\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Input():\n",
    "    def add_start_date(self, start_date):\n",
    "        self.start_date = start_date\n",
    "    def add_end_date(self, end_date):\n",
    "        self.end_date = end_date\n",
    "    def add_files(self, files):\n",
    "        self.files = files\n",
    "    def add_variables(self, variables):\n",
    "        self.variables = variables\n",
    "\n",
    "input_parser = argparse.ArgumentParser()\n",
    "input_parser.add_argument('start_date', type=str, nargs='?', default=\"1990-01-01T00:00:00\")\n",
    "input_parser.add_argument('end_date', type=str, nargs='?', default=\"2022-12-31T23:00:00\")\n",
    "input_parser.add_argument('files', type=list, nargs='?', default=[\n",
    "    \"1991-1992.grib\",\n",
    "    \"2001-2002.grib\",\n",
    "    \"2020.grib\",\n",
    "    \"1993-1994.grib\",\n",
    "    \"2003-2004.grib\",\n",
    "    \"adaptor.mars.internal-1682269507.0764832-26888-6-391bb193-5ba5-403e-a882-ef8b710cb741.grib\",\n",
    "    \"1995-1996.grib\",\n",
    "    \"2005-2006.grib\",\n",
    "    \"adaptor.mars.internal-1682273299.9890068-2454-15-2c5bdfd9-2d84-4efa-b656-f54c57c56c3f.grib\",\n",
    "    \"1997-1998.grib\",\n",
    "    \"2007-2008.grib\"\n",
    "    \"1999-2000.grib\",\n",
    "    \"2009.grib\"])\n",
    "input_parser.add_argument('variables', type=list, nargs='?', default=['tp','2t'])\n",
    "args = input_parser.parse_args()\n",
    "\n",
    "input_path = \"/media/lacie2022/data/meteo/ecmwf/era5/original/reanalysis/\"\n",
    "tmp_path = \"/media/lacie2022/data/meteo/ecmwf/era5/original/reanalysis/tmp/\"\n",
    "mkNestedDir( tmp_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = dt.datetime.strptime( args.start_date, '%Y-%m-%dT%H:%M:%S' )\n",
    "end_date = dt.datetime.strptime( args.end_date, '%Y-%m-%dT%H:%M:%S' )\n",
    "dates = pd.date_range(start_date, end_date, freq='3H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_postgres_connection():\n",
    "\n",
    "    db_name = 'meteo'\n",
    "    db_user = 'postgres'\n",
    "    db_password = 'pgAifa2Bias?'\n",
    "    db_host = '172.20.0.2'\n",
    "\n",
    "    return psycopg2.connect(database=db_name, user=db_user, password=db_password, host=db_host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_point( y, x, epsg=4326, tolerance=0.01 ):\n",
    "\n",
    "    c_id = None\n",
    "\n",
    "    sql_exist = '''\n",
    "        SELECT COUNT(*)\n",
    "        FROM ecmwf.era5_points\n",
    "        WHERE ST_Contains(\n",
    "            ST_Transform(\n",
    "                ST_MakeEnvelope({min_lon}, {min_lat}, {max_lon}, {max_lat}, {epsg}), 4326 ),\n",
    "            era5_points.geom)\n",
    "        LIMIT 1;'''\n",
    "\n",
    "    min_lat = y - tolerance\n",
    "    max_lat = y + tolerance\n",
    "    min_lon = x - tolerance\n",
    "    max_lon = x + tolerance\n",
    "\n",
    "    sql_exist = sql_exist.format(\n",
    "        min_lat=min_lat,\n",
    "        min_lon=min_lon,\n",
    "        max_lat=max_lat,\n",
    "        max_lon=max_lon,\n",
    "        epsg=epsg\n",
    "    )\n",
    "    \n",
    "    # print(sql_exist)\n",
    "\n",
    "    sql_insert = '''\n",
    "        INSERT INTO ecmwf.era5_points(geom)\n",
    "        VALUES ( ST_SetSRID(ST_MakePoint({x},{y}),{epsg}) )\n",
    "        ON CONFLICT DO NOTHING;'''.format(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            epsg=epsg\n",
    "    )\n",
    "\n",
    "    sql_select = '''\n",
    "        SELECT ecmwf.era5_points.id\n",
    "        FROM ecmwf.era5_points\n",
    "        ORDER BY ecmwf.era5_points.geom <#> ST_SetSRID(ST_MakePoint({x},{y}),{epsg})\n",
    "        LIMIT 1;'''.format(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            epsg=epsg\n",
    "        )\n",
    "    \n",
    "    # print(sql_select)\n",
    "\n",
    "    conn = get_postgres_connection()\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            # print(sql_insert)\n",
    "            # cur.execute(sql_insert)\n",
    "            # conn.commit()\n",
    "\n",
    "            # cur.execute(sql_select)\n",
    "            # c_id = int(cur.fetchall()[0][0])\n",
    "            cur.execute(sql_exist)\n",
    "            rows = cur.fetchall()\n",
    "            if rows[0][0] != 0:\n",
    "                cur.execute(sql_select)\n",
    "                c_id = int(cur.fetchall()[0][0])\n",
    "            else:\n",
    "                print(sql_insert)\n",
    "                cur.execute(sql_insert)\n",
    "                conn.commit()\n",
    "                cur.execute(sql_select)\n",
    "                c_id = int(cur.fetchall()[0][0])\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "    return c_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data( y, x, epsg, datetime_UTC, values, variable, um ):\n",
    "\n",
    "    # print(point)\n",
    "\n",
    "    sql_insert = '''\n",
    "        INSERT INTO ecmwf.era5_values(\n",
    "\t        datetime, value, point, variable, um)\n",
    "\t    VALUES ('{datetime}'::timestamp, ARRAY{value},\n",
    "            (\n",
    "                SELECT ecmwf.era5_points.id\n",
    "                FROM ecmwf.era5_points\n",
    "                ORDER BY ST_Distance(ST_SetSRID(ST_MakePoint({x},{y}),{epsg}), ecmwf.era5_points.geom)\n",
    "                LIMIT 1\n",
    "            ), '{variable}', '{um}')\n",
    "        ON CONFLICT DO NOTHING;'''.format(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            epsg=epsg,\n",
    "            datetime=datetime_UTC, \n",
    "            value=values, \n",
    "            variable=variable,\n",
    "            um=um\n",
    "        )\n",
    "    print(sql_insert)\n",
    "    \n",
    "    conn = get_postgres_connection()\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(sql_insert)\n",
    "            conn.commit()\n",
    "    finally:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_on_db( date, var_meta, n_points:int, c_file ):\n",
    "\n",
    "    c_ens_df = pd.read_csv(c_file, nrows=n_points, sep='\\s+')\n",
    "    c_ens_df = c_ens_df.rename(columns={'Value':1})\n",
    "    ens = 2\n",
    "\n",
    "    for i in range((n_points+1),(n_points+1)*10,(n_points+1)):\n",
    "        c_df = pd.read_csv(c_file, skiprows=i, nrows=n_points, sep='\\s+')\n",
    "        c_ens_df[ens] = c_df['Value'].values\n",
    "        ens = ens + 1\n",
    "    \n",
    "    c_ens_df = c_ens_df.set_index(['Latitude','Longitude'])\n",
    "\n",
    "    for idx in c_ens_df.index:\n",
    "\n",
    "        lat = idx[0]\n",
    "        lon = idx[1]\n",
    "        c_id = add_point( lat, lon, epsg=4326 )\n",
    "        add_data( lat, lon, 4326, date, list(c_ens_df.loc[idx].values), var_meta[0], var_meta[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove( tmp_path + '{tmp_txt}.txt'.format(tmp_txt=tmp_txt) )\n",
    "except:\n",
    "    print( 'All clear!' )\n",
    "\n",
    "for c_file in args.files:\n",
    "    print('Processing: ' + str(c_file))\n",
    "    for model_varname in args.variables:\n",
    "\n",
    "        tmp_txt = dt.datetime.strftime(\n",
    "            start_date,\n",
    "            format=\"%Y%m%d\") + '_' + dt.datetime.strftime(\n",
    "                 end_date,\n",
    "                 format=\"%Y%m%d\") + \"_\" + model_varname\n",
    "\n",
    "        if model_varname == 'tp':\n",
    "            variable = 'tp'\n",
    "            um = 'm'\n",
    "\n",
    "        elif model_varname == '2t':\n",
    "            variable = '2t'\n",
    "            um = 'K'\n",
    "\n",
    "        ## create a file for each variable\n",
    "        pre_cmd = '''cdo -selname,{var} {input_path}{file_grib} {input_path}{var}_{file_grib}'''.format(\n",
    "            var = model_varname,\n",
    "            input_path = input_path,\n",
    "            file_grib = c_file\n",
    "        )\n",
    "        print(pre_cmd)\n",
    "        process = subprocess.Popen(pre_cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        stdout, stderr = process.communicate()\n",
    "\n",
    "        ## read the meta info in a table with cdo\n",
    "        meta_cmd = '''cdo -info {input_path}{var}_{file_grib} > {tmp_path}meta.txt'''.format(\n",
    "            var = model_varname,\n",
    "            input_path = input_path,\n",
    "            file_grib = c_file,\n",
    "            tmp_path = tmp_path\n",
    "        )\n",
    "        print(meta_cmd)\n",
    "        process = subprocess.Popen(pre_cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        stdout, stderr = process.communicate()\n",
    "\n",
    "        ## load the meta\n",
    "        df_meta = pd.read_csv('''{tmp_path}meta.txt'''.format(\n",
    "            tmp_path = tmp_path\n",
    "            ), sep='\\s+'\n",
    "        )\n",
    "        \n",
    "        for idx in df_meta.index:\n",
    "            try:\n",
    "                ts = int(df_meta.loc[idx]['-1'])\n",
    "            except:\n",
    "                break\n",
    "\n",
    "            c_date = dt.datetime.strptime(\n",
    "                df_meta.loc[idx]['Date'] + 'T' + df_meta.loc[idx]['Time'],\n",
    "                \"%Y-%m-%dT%H:%M:%S\")\n",
    "            \n",
    "            if not(c_date in dates):\n",
    "                continue\n",
    "\n",
    "            n_points = df_meta.loc[idx]['Gridsize']\n",
    "        \n",
    "            pre_cmd = '''cdo -seltimestep,{step} {input_path}{var}_{file_grib} {input_path}tmp_{idx}_{var}_{file_grib}'''.format(\n",
    "                var = model_varname,\n",
    "                step = ts,\n",
    "                input_path = input_path,\n",
    "                idx = idx,\n",
    "                file_grib = c_file\n",
    "            )\n",
    "            print(pre_cmd)\n",
    "            process = subprocess.Popen(pre_cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout, stderr = process.communicate()\n",
    "               \n",
    "            cmd = '''grib_get_data {input_path}tmp_{idx}_{var}_{file_grib} >> {tmp_path}{tmp_txt}.txt'''.format(\n",
    "                idx = idx,\n",
    "                file_grib = c_file,\n",
    "                input_path = input_path,\n",
    "                tmp_path = tmp_path,\n",
    "                tmp_txt=tmp_txt,\n",
    "                var = model_varname\n",
    "            )\n",
    "            print(cmd)\n",
    "            process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout, stderr = process.communicate()\n",
    "\n",
    "            load_on_db( c_date, (variable, um), int(n_points), tmp_path + '{tmp_txt}.txt'.format(tmp_txt=tmp_txt) )\n",
    "\n",
    "            try:\n",
    "                os.remove( tmp_path + '{tmp_txt}.txt'.format(tmp_txt=tmp_txt) )\n",
    "                os.remove( '{input_path}tmp_{idx}_{var}_{file_grib}'''.format(\n",
    "                    input_path = input_path,\n",
    "                    idx = idx,\n",
    "                    file_grib = c_file,\n",
    "                    var = model_varname\n",
    "                    )\n",
    "                )\n",
    "            except:\n",
    "                continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
